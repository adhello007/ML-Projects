{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280cae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a94186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fba1a",
   "metadata": {},
   "source": [
    "## Just Seeing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc614f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ec24a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7be88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique,counts = np.unique(x_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcff6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd06af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ----  38045844\n",
      "1  ----  22896\n",
      "2  ----  33653\n",
      "3  ----  36040\n",
      "4  ----  38267\n",
      "5  ----  39148\n",
      "6  ----  37692\n",
      "7  ----  38856\n",
      "8  ----  30878\n",
      "9  ----  38234\n",
      "10  ----  35282\n",
      "11  ----  36020\n",
      "12  ----  30139\n",
      "13  ----  40100\n",
      "14  ----  26939\n",
      "15  ----  28869\n",
      "16  ----  29115\n",
      "17  ----  27551\n",
      "18  ----  26849\n",
      "19  ----  34431\n",
      "20  ----  29955\n",
      "21  ----  35496\n",
      "22  ----  26750\n",
      "23  ----  22910\n",
      "24  ----  25950\n",
      "25  ----  29995\n",
      "26  ----  24260\n",
      "27  ----  24025\n",
      "28  ----  25434\n",
      "29  ----  37160\n",
      "30  ----  22913\n",
      "31  ----  26205\n",
      "32  ----  28890\n",
      "33  ----  15556\n",
      "34  ----  19906\n",
      "35  ----  21516\n",
      "36  ----  22128\n",
      "37  ----  24760\n",
      "38  ----  25922\n",
      "39  ----  18250\n",
      "40  ----  20675\n",
      "41  ----  27023\n",
      "42  ----  22349\n",
      "43  ----  21227\n",
      "44  ----  19030\n",
      "45  ----  21122\n",
      "46  ----  17326\n",
      "47  ----  24237\n",
      "48  ----  20083\n",
      "49  ----  17919\n",
      "50  ----  23964\n",
      "51  ----  25003\n",
      "52  ----  14588\n",
      "53  ----  19230\n",
      "54  ----  18195\n",
      "55  ----  18068\n",
      "56  ----  23511\n",
      "57  ----  31905\n",
      "58  ----  14330\n",
      "59  ----  18140\n",
      "60  ----  18144\n",
      "61  ----  18133\n",
      "62  ----  19805\n",
      "63  ----  23909\n",
      "64  ----  46754\n",
      "65  ----  16050\n",
      "66  ----  17514\n",
      "67  ----  15914\n",
      "68  ----  16302\n",
      "69  ----  16742\n",
      "70  ----  19288\n",
      "71  ----  18444\n",
      "72  ----  17313\n",
      "73  ----  19307\n",
      "74  ----  13816\n",
      "75  ----  15875\n",
      "76  ----  17877\n",
      "77  ----  13535\n",
      "78  ----  17569\n",
      "79  ----  18085\n",
      "80  ----  15872\n",
      "81  ----  16527\n",
      "82  ----  21112\n",
      "83  ----  15514\n",
      "84  ----  27088\n",
      "85  ----  25496\n",
      "86  ----  25837\n",
      "87  ----  12645\n",
      "88  ----  15796\n",
      "89  ----  17628\n",
      "90  ----  12695\n",
      "91  ----  17876\n",
      "92  ----  18525\n",
      "93  ----  17225\n",
      "94  ----  16655\n",
      "95  ----  16244\n",
      "96  ----  17902\n",
      "97  ----  14246\n",
      "98  ----  16820\n",
      "99  ----  17710\n",
      "100  ----  15217\n",
      "101  ----  14210\n",
      "102  ----  21721\n",
      "103  ----  14854\n",
      "104  ----  16395\n",
      "105  ----  14871\n",
      "106  ----  18334\n",
      "107  ----  16385\n",
      "108  ----  17914\n",
      "109  ----  18293\n",
      "110  ----  15737\n",
      "111  ----  16052\n",
      "112  ----  18288\n",
      "113  ----  19994\n",
      "114  ----  24774\n",
      "115  ----  15056\n",
      "116  ----  19329\n",
      "117  ----  14702\n",
      "118  ----  17061\n",
      "119  ----  15472\n",
      "120  ----  16419\n",
      "121  ----  17300\n",
      "122  ----  16392\n",
      "123  ----  17752\n",
      "124  ----  13804\n",
      "125  ----  16490\n",
      "126  ----  16800\n",
      "127  ----  16455\n",
      "128  ----  74946\n",
      "129  ----  16409\n",
      "130  ----  17908\n",
      "131  ----  19269\n",
      "132  ----  18685\n",
      "133  ----  15030\n",
      "134  ----  15490\n",
      "135  ----  16616\n",
      "136  ----  16088\n",
      "137  ----  17451\n",
      "138  ----  17378\n",
      "139  ----  19446\n",
      "140  ----  17683\n",
      "141  ----  27102\n",
      "142  ----  17965\n",
      "143  ----  15986\n",
      "144  ----  18827\n",
      "145  ----  18303\n",
      "146  ----  15873\n",
      "147  ----  16743\n",
      "148  ----  17012\n",
      "149  ----  16590\n",
      "150  ----  16943\n",
      "151  ----  21650\n",
      "152  ----  17821\n",
      "153  ----  15547\n",
      "154  ----  17938\n",
      "155  ----  18754\n",
      "156  ----  18648\n",
      "157  ----  14733\n",
      "158  ----  16788\n",
      "159  ----  15946\n",
      "160  ----  18066\n",
      "161  ----  17143\n",
      "162  ----  17994\n",
      "163  ----  18337\n",
      "164  ----  15435\n",
      "165  ----  15288\n",
      "166  ----  15029\n",
      "167  ----  14355\n",
      "168  ----  25069\n",
      "169  ----  25562\n",
      "170  ----  29853\n",
      "171  ----  16744\n",
      "172  ----  18505\n",
      "173  ----  19517\n",
      "174  ----  16904\n",
      "175  ----  16539\n",
      "176  ----  17251\n",
      "177  ----  16800\n",
      "178  ----  16862\n",
      "179  ----  18169\n",
      "180  ----  17153\n",
      "181  ----  17183\n",
      "182  ----  16052\n",
      "183  ----  20007\n",
      "184  ----  18052\n",
      "185  ----  17278\n",
      "186  ----  17009\n",
      "187  ----  16589\n",
      "188  ----  17257\n",
      "189  ----  18658\n",
      "190  ----  20487\n",
      "191  ----  51987\n",
      "192  ----  19899\n",
      "193  ----  18840\n",
      "194  ----  18961\n",
      "195  ----  20001\n",
      "196  ----  22659\n",
      "197  ----  23195\n",
      "198  ----  26112\n",
      "199  ----  18878\n",
      "200  ----  18097\n",
      "201  ----  17640\n",
      "202  ----  19653\n",
      "203  ----  28907\n",
      "204  ----  18440\n",
      "205  ----  19399\n",
      "206  ----  21994\n",
      "207  ----  20848\n",
      "208  ----  18141\n",
      "209  ----  19604\n",
      "210  ----  21901\n",
      "211  ----  22590\n",
      "212  ----  23084\n",
      "213  ----  25289\n",
      "214  ----  25724\n",
      "215  ----  24176\n",
      "216  ----  21708\n",
      "217  ----  24890\n",
      "218  ----  21828\n",
      "219  ----  19632\n",
      "220  ----  20554\n",
      "221  ----  24794\n",
      "222  ----  25839\n",
      "223  ----  26221\n",
      "224  ----  24175\n",
      "225  ----  27285\n",
      "226  ----  35378\n",
      "227  ----  25350\n",
      "228  ----  29370\n",
      "229  ----  23646\n",
      "230  ----  26957\n",
      "231  ----  29365\n",
      "232  ----  30253\n",
      "233  ----  36800\n",
      "234  ----  33219\n",
      "235  ----  29130\n",
      "236  ----  31555\n",
      "237  ----  29676\n",
      "238  ----  26914\n",
      "239  ----  27474\n",
      "240  ----  33422\n",
      "241  ----  35573\n",
      "242  ----  31218\n",
      "243  ----  37029\n",
      "244  ----  37199\n",
      "245  ----  35397\n",
      "246  ----  33844\n",
      "247  ----  37941\n",
      "248  ----  35418\n",
      "249  ----  39342\n",
      "250  ----  59559\n",
      "251  ----  117808\n",
      "252  ----  653888\n",
      "253  ----  1513207\n",
      "254  ----  801557\n",
      "255  ----  314282\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for i in range(len(unique)):\n",
    "    print(unique[i] ,\" ---- \",counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40027157",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_unnormalized = x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8775a",
   "metadata": {},
   "source": [
    "## Normalize the x-labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d2b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4de2f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00392157, 0.00784314, 0.01176471, 0.01568627,\n",
       "       0.01960784, 0.02352941, 0.02745098, 0.03137255, 0.03529412,\n",
       "       0.03921569, 0.04313725, 0.04705882, 0.05098039, 0.05490196,\n",
       "       0.05882353, 0.0627451 , 0.06666667, 0.07058824, 0.0745098 ,\n",
       "       0.07843137, 0.08235294, 0.08627451, 0.09019608, 0.09411765,\n",
       "       0.09803922, 0.10196078, 0.10588235, 0.10980392, 0.11372549,\n",
       "       0.11764706, 0.12156863, 0.1254902 , 0.12941176, 0.13333333,\n",
       "       0.1372549 , 0.14117647, 0.14509804, 0.14901961, 0.15294118,\n",
       "       0.15686275, 0.16078431, 0.16470588, 0.16862745, 0.17254902,\n",
       "       0.17647059, 0.18039216, 0.18431373, 0.18823529, 0.19215686,\n",
       "       0.19607843, 0.2       , 0.20392157, 0.20784314, 0.21176471,\n",
       "       0.21568627, 0.21960784, 0.22352941, 0.22745098, 0.23137255,\n",
       "       0.23529412, 0.23921569, 0.24313725, 0.24705882, 0.25098039,\n",
       "       0.25490196, 0.25882353, 0.2627451 , 0.26666667, 0.27058824,\n",
       "       0.2745098 , 0.27843137, 0.28235294, 0.28627451, 0.29019608,\n",
       "       0.29411765, 0.29803922, 0.30196078, 0.30588235, 0.30980392,\n",
       "       0.31372549, 0.31764706, 0.32156863, 0.3254902 , 0.32941176,\n",
       "       0.33333333, 0.3372549 , 0.34117647, 0.34509804, 0.34901961,\n",
       "       0.35294118, 0.35686275, 0.36078431, 0.36470588, 0.36862745,\n",
       "       0.37254902, 0.37647059, 0.38039216, 0.38431373, 0.38823529,\n",
       "       0.39215686, 0.39607843, 0.4       , 0.40392157, 0.40784314,\n",
       "       0.41176471, 0.41568627, 0.41960784, 0.42352941, 0.42745098,\n",
       "       0.43137255, 0.43529412, 0.43921569, 0.44313725, 0.44705882,\n",
       "       0.45098039, 0.45490196, 0.45882353, 0.4627451 , 0.46666667,\n",
       "       0.47058824, 0.4745098 , 0.47843137, 0.48235294, 0.48627451,\n",
       "       0.49019608, 0.49411765, 0.49803922, 0.50196078, 0.50588235,\n",
       "       0.50980392, 0.51372549, 0.51764706, 0.52156863, 0.5254902 ,\n",
       "       0.52941176, 0.53333333, 0.5372549 , 0.54117647, 0.54509804,\n",
       "       0.54901961, 0.55294118, 0.55686275, 0.56078431, 0.56470588,\n",
       "       0.56862745, 0.57254902, 0.57647059, 0.58039216, 0.58431373,\n",
       "       0.58823529, 0.59215686, 0.59607843, 0.6       , 0.60392157,\n",
       "       0.60784314, 0.61176471, 0.61568627, 0.61960784, 0.62352941,\n",
       "       0.62745098, 0.63137255, 0.63529412, 0.63921569, 0.64313725,\n",
       "       0.64705882, 0.65098039, 0.65490196, 0.65882353, 0.6627451 ,\n",
       "       0.66666667, 0.67058824, 0.6745098 , 0.67843137, 0.68235294,\n",
       "       0.68627451, 0.69019608, 0.69411765, 0.69803922, 0.70196078,\n",
       "       0.70588235, 0.70980392, 0.71372549, 0.71764706, 0.72156863,\n",
       "       0.7254902 , 0.72941176, 0.73333333, 0.7372549 , 0.74117647,\n",
       "       0.74509804, 0.74901961, 0.75294118, 0.75686275, 0.76078431,\n",
       "       0.76470588, 0.76862745, 0.77254902, 0.77647059, 0.78039216,\n",
       "       0.78431373, 0.78823529, 0.79215686, 0.79607843, 0.8       ,\n",
       "       0.80392157, 0.80784314, 0.81176471, 0.81568627, 0.81960784,\n",
       "       0.82352941, 0.82745098, 0.83137255, 0.83529412, 0.83921569,\n",
       "       0.84313725, 0.84705882, 0.85098039, 0.85490196, 0.85882353,\n",
       "       0.8627451 , 0.86666667, 0.87058824, 0.8745098 , 0.87843137,\n",
       "       0.88235294, 0.88627451, 0.89019608, 0.89411765, 0.89803922,\n",
       "       0.90196078, 0.90588235, 0.90980392, 0.91372549, 0.91764706,\n",
       "       0.92156863, 0.9254902 , 0.92941176, 0.93333333, 0.9372549 ,\n",
       "       0.94117647, 0.94509804, 0.94901961, 0.95294118, 0.95686275,\n",
       "       0.96078431, 0.96470588, 0.96862745, 0.97254902, 0.97647059,\n",
       "       0.98039216, 0.98431373, 0.98823529, 0.99215686, 0.99607843,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b1ac77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320f4b1",
   "metadata": {},
   "source": [
    "## Reshape it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21aec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(60000,784,))\n",
    "x_test = np.reshape(x_test,(60000,784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ded1683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479604b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4933710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee41003",
   "metadata": {},
   "source": [
    "## To Visualize One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7524dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaI0lEQVR4nO3df2jU9x3H8dfVH1d1lytBk7vUmGVF202dpWrVYP3R1cxApf4oWMtGZEPa+YOJ/cGsDNNBjdgpRdI6V0amW239Y9a6KdUMTXRkijpdRYtYjDOdCcFM72LUSMxnf4hHz1j1e975vkueD/iCufu+vY/ffuvTby75xueccwIAwMBD1gsAAHRfRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjpab2AW3V0dOjcuXMKBALy+XzWywEAeOScU0tLi/Ly8vTQQ3e+1km7CJ07d075+fnWywAA3Kf6+noNHDjwjvuk3afjAoGA9RIAAElwL3+fpyxCH3zwgQoLC/Xwww9r5MiR2rdv3z3N8Sk4AOga7uXv85REaPPmzVq8eLGWLVumI0eO6JlnnlFJSYnOnj2bipcDAGQoXyruoj1mzBg99dRTWrduXeyx73//+5o+fbrKy8vvOBuNRhUMBpO9JADAAxaJRJSVlXXHfZJ+JXTt2jUdPnxYxcXFcY8XFxertra20/5tbW2KRqNxGwCge0h6hM6fP6/r168rNzc37vHc3Fw1NjZ22r+8vFzBYDC28ZVxANB9pOwLE259Q8o5d9s3qZYuXapIJBLb6uvrU7UkAECaSfr3CfXv3189evTodNXT1NTU6epIkvx+v/x+f7KXAQDIAEm/Eurdu7dGjhypqqqquMerqqpUVFSU7JcDAGSwlNwxYcmSJfrpT3+qUaNGady4cfr973+vs2fP6tVXX03FywEAMlRKIjR79mw1NzfrN7/5jRoaGjRs2DDt2LFDBQUFqXg5AECGSsn3Cd0Pvk8IALoGk+8TAgDgXhEhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmelovAEgnPXr08DwTDAZTsJLkWLhwYUJzffv29Tzz+OOPe55ZsGCB55nf/va3nmfmzJnjeUaSrl696nlm5cqVnmfefvttzzNdBVdCAAAzRAgAYCbpESorK5PP54vbQqFQsl8GANAFpOQ9oaFDh+rvf/977ONEPs8OAOj6UhKhnj17cvUDALirlLwndOrUKeXl5amwsFAvvfSSTp8+/a37trW1KRqNxm0AgO4h6REaM2aMNm7cqJ07d+rDDz9UY2OjioqK1NzcfNv9y8vLFQwGY1t+fn6ylwQASFNJj1BJSYlmzZql4cOH67nnntP27dslSRs2bLjt/kuXLlUkEolt9fX1yV4SACBNpfybVfv166fhw4fr1KlTt33e7/fL7/enehkAgDSU8u8Tamtr05dffqlwOJzqlwIAZJikR+j1119XTU2N6urqdODAAb344ouKRqMqLS1N9ksBADJc0j8d9/XXX2vOnDk6f/68BgwYoLFjx2r//v0qKChI9ksBADJc0iP0ySefJPu3RJoaNGiQ55nevXt7nikqKvI8M378eM8zkvTII494npk1a1ZCr9XVfP31155n1q5d63lmxowZnmdaWlo8z0jSv//9b88zNTU1Cb1Wd8W94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAMz7nnLNexDdFo1EFg0HrZXQrTz75ZEJzu3fv9jzDf9vM0NHR4XnmZz/7meeZS5cueZ5JRENDQ0JzFy5c8Dxz8uTJhF6rK4pEIsrKyrrjPlwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwExP6wXA3tmzZxOaa25u9jzDXbRvOHDggOeZixcvep6ZPHmy5xlJunbtmueZP/3pTwm9Fro3roQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADPcwBT63//+l9DcG2+84Xnm+eef9zxz5MgRzzNr1671PJOoo0ePep6ZMmWK55nW1lbPM0OHDvU8I0m//OUvE5oDvOJKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAw43POOetFfFM0GlUwGLReBlIkKyvL80xLS4vnmfXr13uekaSf//znnmd+8pOfeJ75+OOPPc8AmSYSidz1/3muhAAAZogQAMCM5wjt3btX06ZNU15ennw+n7Zu3Rr3vHNOZWVlysvLU58+fTRp0iQdP348WesFAHQhniPU2tqqESNGqKKi4rbPr1q1SmvWrFFFRYUOHjyoUCikKVOmJPR5fQBA1+b5J6uWlJSopKTkts855/Tee+9p2bJlmjlzpiRpw4YNys3N1aZNm/TKK6/c32oBAF1KUt8TqqurU2Njo4qLi2OP+f1+TZw4UbW1tbedaWtrUzQajdsAAN1DUiPU2NgoScrNzY17PDc3N/bcrcrLyxUMBmNbfn5+MpcEAEhjKfnqOJ/PF/exc67TYzctXbpUkUgkttXX16diSQCANOT5PaE7CYVCkm5cEYXD4djjTU1Nna6ObvL7/fL7/clcBgAgQyT1SqiwsFChUEhVVVWxx65du6aamhoVFRUl86UAAF2A5yuhS5cu6auvvop9XFdXp6NHjyo7O1uDBg3S4sWLtWLFCg0ePFiDBw/WihUr1LdvX7388stJXTgAIPN5jtChQ4c0efLk2MdLliyRJJWWluqPf/yj3nzzTV25ckXz58/XhQsXNGbMGO3atUuBQCB5qwYAdAncwBRd0rvvvpvQ3M1/VHlRU1Pjeea5557zPNPR0eF5BrDEDUwBAGmNCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriLNrqkfv36JTT317/+1fPMxIkTPc+UlJR4ntm1a5fnGcASd9EGAKQ1IgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMNzAFvuGxxx7zPPOvf/3L88zFixc9z+zZs8fzzKFDhzzPSNL777/veSbN/ipBGuAGpgCAtEaEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpsB9mjFjhueZyspKzzOBQMDzTKLeeustzzMbN270PNPQ0OB5BpmDG5gCANIaEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5gCBoYNG+Z5Zs2aNZ5nfvSjH3meSdT69es9z7zzzjueZ/773/96noENbmAKAEhrRAgAYMZzhPbu3atp06YpLy9PPp9PW7dujXt+7ty58vl8cdvYsWOTtV4AQBfiOUKtra0aMWKEKioqvnWfqVOnqqGhIbbt2LHjvhYJAOiaenodKCkpUUlJyR338fv9CoVCCS8KANA9pOQ9oerqauXk5GjIkCGaN2+empqavnXftrY2RaPRuA0A0D0kPUIlJSX66KOPtHv3bq1evVoHDx7Us88+q7a2ttvuX15ermAwGNvy8/OTvSQAQJry/Om4u5k9e3bs18OGDdOoUaNUUFCg7du3a+bMmZ32X7p0qZYsWRL7OBqNEiIA6CaSHqFbhcNhFRQU6NSpU7d93u/3y+/3p3oZAIA0lPLvE2publZ9fb3C4XCqXwoAkGE8XwldunRJX331Vezjuro6HT16VNnZ2crOzlZZWZlmzZqlcDisM2fO6K233lL//v01Y8aMpC4cAJD5PEfo0KFDmjx5cuzjm+/nlJaWat26dTp27Jg2btyoixcvKhwOa/Lkydq8ebMCgUDyVg0A6BK4gSmQIR555BHPM9OmTUvotSorKz3P+Hw+zzO7d+/2PDNlyhTPM7DBDUwBAGmNCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriLNoBO2traPM/07On9BzW3t7d7nvnxj3/seaa6utrzDO4fd9EGAKQ1IgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMCM9zsOArhvP/zhDz3PvPjii55nRo8e7XlGSuxmpIk4ceKE55m9e/emYCWwwpUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5gC3/D44497nlm4cKHnmZkzZ3qeCYVCnmcepOvXr3ueaWho8DzT0dHheQbpiyshAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMNzBF2kvkxp1z5sxJ6LUSuRnpd7/73YReK50dOnTI88w777zjeWbbtm2eZ9C1cCUEADBDhAAAZjxFqLy8XKNHj1YgEFBOTo6mT5+ukydPxu3jnFNZWZny8vLUp08fTZo0ScePH0/qogEAXYOnCNXU1GjBggXav3+/qqqq1N7eruLiYrW2tsb2WbVqldasWaOKigodPHhQoVBIU6ZMUUtLS9IXDwDIbJ6+MOHzzz+P+7iyslI5OTk6fPiwJkyYIOec3nvvPS1btiz2kyM3bNig3Nxcbdq0Sa+88kryVg4AyHj39Z5QJBKRJGVnZ0uS6urq1NjYqOLi4tg+fr9fEydOVG1t7W1/j7a2NkWj0bgNANA9JBwh55yWLFmi8ePHa9iwYZKkxsZGSVJubm7cvrm5ubHnblVeXq5gMBjb8vPzE10SACDDJByhhQsX6osvvtDHH3/c6Tmfzxf3sXOu02M3LV26VJFIJLbV19cnuiQAQIZJ6JtVFy1apG3btmnv3r0aOHBg7PGb31TY2NiocDgce7ypqanT1dFNfr9ffr8/kWUAADKcpysh55wWLlyoLVu2aPfu3SosLIx7vrCwUKFQSFVVVbHHrl27ppqaGhUVFSVnxQCALsPTldCCBQu0adMmffbZZwoEArH3eYLBoPr06SOfz6fFixdrxYoVGjx4sAYPHqwVK1aob9++evnll1PyBwAAZC5PEVq3bp0kadKkSXGPV1ZWau7cuZKkN998U1euXNH8+fN14cIFjRkzRrt27VIgEEjKggEAXYfPOeesF/FN0WhUwWDQehm4B9/2Pt+d/OAHP/A8U1FR4XnmiSee8DyT7g4cOOB55t13303otT777DPPMx0dHQm9FrquSCSirKysO+7DveMAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgJqGfrIr0lZ2d7Xlm/fr1Cb3Wk08+6Xnme9/7XkKvlc5qa2s9z6xevdrzzM6dOz3PXLlyxfMM8CBxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpg/ImDFjPM+88cYbnmeefvppzzOPPvqo55l0d/ny5YTm1q5d63lmxYoVnmdaW1s9zwBdEVdCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZbmD6gMyYMeOBzDxIJ06c8Dzzt7/9zfNMe3u755nVq1d7npGkixcvJjQHIDFcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZnzOOWe9iG+KRqMKBoPWywAA3KdIJKKsrKw77sOVEADADBECAJjxFKHy8nKNHj1agUBAOTk5mj59uk6ePBm3z9y5c+Xz+eK2sWPHJnXRAICuwVOEampqtGDBAu3fv19VVVVqb29XcXGxWltb4/abOnWqGhoaYtuOHTuSumgAQNfg6Serfv7553EfV1ZWKicnR4cPH9aECRNij/v9foVCoeSsEADQZd3Xe0KRSESSlJ2dHfd4dXW1cnJyNGTIEM2bN09NTU3f+nu0tbUpGo3GbQCA7iHhL9F2zumFF17QhQsXtG/fvtjjmzdv1ne+8x0VFBSorq5Ov/71r9Xe3q7Dhw/L7/d3+n3Kysr09ttvJ/4nAACkpXv5Em25BM2fP98VFBS4+vr6O+537tw516tXL/eXv/zlts9fvXrVRSKR2FZfX+8ksbGxsbFl+BaJRO7aEk/vCd20aNEibdu2TXv37tXAgQPvuG84HFZBQYFOnTp12+f9fv9tr5AAAF2fpwg557Ro0SJ9+umnqq6uVmFh4V1nmpubVV9fr3A4nPAiAQBdk6cvTFiwYIH+/Oc/a9OmTQoEAmpsbFRjY6OuXLkiSbp06ZJef/11/fOf/9SZM2dUXV2tadOmqX///poxY0ZK/gAAgAzm5X0gfcvn/SorK51zzl2+fNkVFxe7AQMGuF69erlBgwa50tJSd/bs2Xt+jUgkYv55TDY2Nja2+9/u5T0hbmAKAEgJbmAKAEhrRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzaRch55z1EgAASXAvf5+nXYRaWlqslwAASIJ7+fvc59Ls0qOjo0Pnzp1TIBCQz+eLey4ajSo/P1/19fXKysoyWqE9jsMNHIcbOA43cBxuSIfj4JxTS0uL8vLy9NBDd77W6fmA1nTPHnroIQ0cOPCO+2RlZXXrk+wmjsMNHIcbOA43cBxusD4OwWDwnvZLu0/HAQC6DyIEADCTURHy+/1avny5/H6/9VJMcRxu4DjcwHG4geNwQ6Ydh7T7wgQAQPeRUVdCAICuhQgBAMwQIQCAGSIEADCTURH64IMPVFhYqIcfflgjR47Uvn37rJf0QJWVlcnn88VtoVDIelkpt3fvXk2bNk15eXny+XzaunVr3PPOOZWVlSkvL099+vTRpEmTdPz4cZvFptDdjsPcuXM7nR9jx461WWyKlJeXa/To0QoEAsrJydH06dN18uTJuH26w/lwL8chU86HjInQ5s2btXjxYi1btkxHjhzRM888o5KSEp09e9Z6aQ/U0KFD1dDQENuOHTtmvaSUa21t1YgRI1RRUXHb51etWqU1a9aooqJCBw8eVCgU0pQpU7rcfQjvdhwkaerUqXHnx44dOx7gClOvpqZGCxYs0P79+1VVVaX29nYVFxertbU1tk93OB/u5ThIGXI+uAzx9NNPu1dffTXusSeeeML96le/MlrRg7d8+XI3YsQI62WYkuQ+/fTT2McdHR0uFAq5lStXxh67evWqCwaD7ne/+53BCh+MW4+Dc86Vlpa6F154wWQ9VpqampwkV1NT45zrvufDrcfBucw5HzLiSujatWs6fPiwiouL4x4vLi5WbW2t0apsnDp1Snl5eSosLNRLL72k06dPWy/JVF1dnRobG+PODb/fr4kTJ3a7c0OSqqurlZOToyFDhmjevHlqamqyXlJKRSIRSVJ2drak7ns+3HocbsqE8yEjInT+/Hldv35dubm5cY/n5uaqsbHRaFUP3pgxY7Rx40bt3LlTH374oRobG1VUVKTm5mbrpZm5+d+/u58bklRSUqKPPvpIu3fv1urVq3Xw4EE9++yzamtrs15aSjjntGTJEo0fP17Dhg2T1D3Ph9sdBylzzoe0u4v2ndz6ox2cc50e68pKSkpivx4+fLjGjRunxx57TBs2bNCSJUsMV2avu58bkjR79uzYr4cNG6ZRo0apoKBA27dv18yZMw1XlhoLFy7UF198oX/84x+dnutO58O3HYdMOR8y4kqof//+6tGjR6d/yTQ1NXX6F0930q9fPw0fPlynTp2yXoqZm18dyLnRWTgcVkFBQZc8PxYtWqRt27Zpz549cT/6pbudD992HG4nXc+HjIhQ7969NXLkSFVVVcU9XlVVpaKiIqNV2Wtra9OXX36pcDhsvRQzhYWFCoVCcefGtWvXVFNT063PDUlqbm5WfX19lzo/nHNauHChtmzZot27d6uwsDDu+e5yPtztONxO2p4Phl8U4cknn3zievXq5f7whz+4EydOuMWLF7t+/fq5M2fOWC/tgXnttddcdXW1O336tNu/f797/vnnXSAQ6PLHoKWlxR05csQdOXLESXJr1qxxR44ccf/5z3+cc86tXLnSBYNBt2XLFnfs2DE3Z84cFw6HXTQaNV55ct3pOLS0tLjXXnvN1dbWurq6Ordnzx43btw49+ijj3ap4/CLX/zCBYNBV11d7RoaGmLb5cuXY/t0h/Phbschk86HjImQc869//77rqCgwPXu3ds99dRTcV+O2B3Mnj3bhcNh16tXL5eXl+dmzpzpjh8/br2slNuzZ4+T1GkrLS11zt34stzly5e7UCjk/H6/mzBhgjt27JjtolPgTsfh8uXLrri42A0YMMD16tXLDRo0yJWWlrqzZ89aLzupbvfnl+QqKytj+3SH8+FuxyGTzgd+lAMAwExGvCcEAOiaiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz/wdVbyhNmNF0pQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "eg_img = np.array(x_train[0],dtype ='float')\n",
    "pixels = eg_img.reshape((28,28))\n",
    "plt.imshow(pixels,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbdb471b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00392157, 0.00784314, 0.01176471, 0.03529412,\n",
       "       0.04313725, 0.05490196, 0.0627451 , 0.07058824, 0.09019608,\n",
       "       0.09411765, 0.09803922, 0.10196078, 0.10588235, 0.11764706,\n",
       "       0.1372549 , 0.14117647, 0.15294118, 0.16862745, 0.17647059,\n",
       "       0.18039216, 0.19215686, 0.21568627, 0.21960784, 0.25098039,\n",
       "       0.25882353, 0.2745098 , 0.30588235, 0.31372549, 0.31764706,\n",
       "       0.32156863, 0.35294118, 0.36470588, 0.36862745, 0.41960784,\n",
       "       0.42352941, 0.44705882, 0.46666667, 0.49411765, 0.49803922,\n",
       "       0.50980392, 0.51764706, 0.52156863, 0.52941176, 0.53333333,\n",
       "       0.54509804, 0.58039216, 0.58823529, 0.60392157, 0.61176471,\n",
       "       0.62745098, 0.65098039, 0.66666667, 0.67058824, 0.6745098 ,\n",
       "       0.68627451, 0.71372549, 0.71764706, 0.72941176, 0.73333333,\n",
       "       0.74509804, 0.76470588, 0.77647059, 0.78823529, 0.80392157,\n",
       "       0.81176471, 0.83137255, 0.83529412, 0.85882353, 0.86666667,\n",
       "       0.88235294, 0.88627451, 0.89803922, 0.93333333, 0.94117647,\n",
       "       0.94509804, 0.94901961, 0.95686275, 0.96862745, 0.97647059,\n",
       "       0.98039216, 0.98431373, 0.98823529, 0.99215686, 1.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e333070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebb2f7",
   "metadata": {},
   "source": [
    "## CHOICE - You can either one hot code or not it depends on you \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8460b0",
   "metadata": {},
   "source": [
    "you can use categorical_crossentropy loss with one hot encoding and sparse_categorical_crossentropy without one hot encoding. \n",
    "so in the end the loss function calculation does not get affected. but in general it may increase the computation if we one hot encode it. but for mnist it doesnt really make a difference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cee53e",
   "metadata": {},
   "source": [
    "## Create a Model - with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8107d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f897352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(784,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94105ce",
   "metadata": {},
   "source": [
    "## Specify Loss & Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "198168af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d41391",
   "metadata": {},
   "source": [
    "## Perform KFOLD and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca8a0c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.7008 - accuracy: 0.8069\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.9024\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2674 - accuracy: 0.9224\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2335 - accuracy: 0.9319\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2046 - accuracy: 0.9405\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1844 - accuracy: 0.9470\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9513\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1520 - accuracy: 0.9561\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1418 - accuracy: 0.9587\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1382 - accuracy: 0.9594\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "Mean accurcay:  0.9460166666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import accuracy_score \n",
    "kf = KFold(n_splits=10)\n",
    "accuracies = []\n",
    "for train_index,test_index in kf.split(x_train):\n",
    "    x_train_fold,x_val_fold = x_train[train_index],x_train[test_index]\n",
    "    y_train_fold,y_val_fold = y_train[train_index],y_train[test_index]\n",
    "    \n",
    "    model.fit(x_train_fold,y_train_fold)\n",
    "    y_prediction = model.predict(x_val_fold)\n",
    "    y_preds = np.argmax(y_prediction,axis = 1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val_fold,y_preds)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(\"Mean accurcay: \", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ae2fb",
   "metadata": {},
   "source": [
    "## Evaluate your model - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9529d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1179 - accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "x_test = np.reshape(x_test,(10000,784,))\n",
    "accuracy = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d4f20",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7dadfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predcition = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35137bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9909879e-05, 8.6213396e-07, 8.1503828e-04, 2.0867884e-03,\n",
       "       9.6582619e-07, 2.1720283e-05, 2.8830620e-09, 9.9659985e-01,\n",
       "       7.0846974e-05, 3.8409760e-04], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predcition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "153e8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.argmax(y_predcition,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8290c240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a56119a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c324697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accuracy of the predictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15fea74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_pred_final,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc3354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
